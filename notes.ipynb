{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph-Transformer Molecular-Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to consider / Hyperparameters:\n",
    "\n",
    "1. d_model: the dimension of the embeddings\n",
    "2. num_heads: the number of heads in the self-attention module.\n",
    "3. drop_prob: probability to drop neurons.\n",
    "4. max_sequence_length: the max length of the input sequence\n",
    "5. ffn_hidden: the maximum number of neurons in a ffn hidden layer.\n",
    "6. num_encoder = number of encoder units in the structure.\n",
    "\n",
    "![Alt text](./images/Input%20Molecular%20Data%20(1).jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Attention(Q,K,V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import ZINC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.dropbox.com/s/feo9qle74kg48gy/molecules.zip?dl=1\n",
      "Extracting Data/zinc_data/molecules.zip\n",
      "Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/train.index\n",
      "Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/val.index\n",
      "Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/test.index\n",
      "Processing...\n",
      "Processing train dataset: 100%|██████████| 220011/220011 [00:12<00:00, 17406.20it/s]\n",
      "Processing val dataset: 100%|██████████| 24445/24445 [00:01<00:00, 13075.85it/s]\n",
      "Processing test dataset: 100%|██████████| 5000/5000 [00:00<00:00, 16381.85it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = ZINC(root = \"./Data/zinc_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220011\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "first_data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.0464])\n",
      "tensor([0.4907])\n",
      "tensor([1.0851])\n",
      "tensor([-1.9355])\n",
      "tensor([1.5754])\n",
      "tensor([0.0451])\n",
      "tensor([-1.0224])\n",
      "tensor([-0.1079])\n",
      "tensor([2.5177])\n",
      "tensor([1.1925])\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(dataset[_].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0851])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2].y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow: Data in ./Data folder, config file all good to go.\n",
    "1) model reads coordinates, atom species, energies from the ./Data files, and split them in portions according to the config specification.\n",
    "2) additional energy processing including subtraction of self_energy\n",
    "3) Package everything into PyGDataLoader -> train_loader ready to be sent in to training function\n",
    "4) Training function takes in numerous parameters from the config file\n",
    "5) y data normalized using training values, std and mean recorded\n",
    "6) printing function, writing/tensorboard writer setup\n",
    "7) train the model, no k-fold, the model with the lowest validation loss saved, when evaluating, validation y values were de-normed using pre-saved std and mean\n",
    "8) Test set evalution using the best model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
